<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AnyGraph: Graph Foundation Model in the Wild</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-08-20">20 Aug 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lianghao</forename><surname>Xia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Chao</forename><surname>Huang</surname></persName>
							<email>chuang7@hku.hkgithub</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">AnyGraph: Graph Foundation Model in the Wild</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-08-20">20 Aug 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">39D6149AC312B8B6FA488EC42671B469</idno>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<idno type="arXiv">arXiv:2408.10700v1[cs.LG]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-01-17T21:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The growing ubiquity of relational data structured as graphs has underscored the need for graph learning models with exceptional generalization capabilities. However, current approaches often struggle to effectively extract generalizable insights, frequently requiring extensive fine-tuning and limiting their versatility. Graph foundation models offer a transformative solution, with the potential to learn robust, generalizable representations from graph data. This enables more effective and adaptable applications across a wide spectrum of tasks and domains. In this work, we investigate a unified graph model, AnyGraph, designed to handle key challenges: i) Structure Heterogenity. Addressing distribution shift in graph structural information; ii) Feature Heterogenity. Handling diverse feature representation spaces across graph datasets; iii) Fast Adaptation. Efficiently adapting the model to new graph domains; iv) Scaling Law Emergence. Enabling the model to exhibit scaling law behavior, where its performance scales favorably with the amount of data and parameter sizes. To tackle these critical challenges, we build the AnyGraph upon a Graph Mixture-of-Experts (MoE) architecture. This approach empowers the model to effectively manage both the in-domain and cross-domain distribution shift concerning structure-level and feature-level heterogeneity. Furthermore, a lightweight graph expert routing mechanism is proposed to facilitate AnyGraph's fast adaptability to new data and domains. Our extensive experiments on diverse 38 graph datasets have demonstrated the strong zero-shot learning performance of AnyGraph across diverse graph domains with significant distribution shift. Furthermore, we have validated the model's fast adaptation ability and scaling law emergence, showcasing its versatility.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The growing ubiquity of relational data in the form of graphs has underscored the pressing need for advanced graph learning models that excel at generalization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13]</ref>. As real-world applications of graph-structured data continue to proliferate across diverse domains, including social networks, academic networks, transportation systems, and biological networks, the ability of graph learning models to effectively handle distribution shifts and adapt to new graph domains has become increasingly crucial <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref>. Developing models with robust zero-shot learning performance and fast adaptation capabilities can unlock transformative opportunities for leveraging the rich insights encoded within graph data.</p><p>The field of graph learning has seen significant advancements in recent years, largely driven by the power of Graph Neural Networks (GNNs) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b30">31]</ref>. However, the current state-of-the-art models often fall short when it comes to truly generalizable performance. Existing approaches tend to be heavily reliant on arduous finetuning processes, making them ill-equipped to handle the diverse array of graph structures and distributions encountered in realworld applications. This inability to adapt swiftly and seamlessly to novel graph domains poses a critical barrier to the widespread adoption of graph learning technologies. Therefore, addressing this challenge is of paramount importance if we are to fully harness the transformative potential of graph-based insights.</p><p>Inspired by the principles that have driven the development of successful foundation models in understanding vision and language data <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>, the concept of a versatile graph foundation model holds immense potential to unlock new frontiers in graph learning. By learning rich, transferable representations from diverse graphstructured data, such a model can be efficiently adapted to a wide array of graph domains and tasks. However, building an effective and adaptive graph foundation model is not a trivial endeavor.</p><p>Several key challenges must be overcome, including: (i) Structure Heterogeneity. The development of versatile graph models faces the challenge of accommodating diverse structural properties and data distributions in various graph datasets. For instance, graphs can exhibit substantial heterogeneity in node degree distributions, ranging from homogeneous to highly skewed patterns. Similarly, graph structures can vary greatly in complexity, from simple topologies to intricate, hierarchical arrangements. These structural variations can significantly impact the performance and generalization of graph learning algorithms. Effectively addressing this diversity is critical for developing unified models that can thrive across a wide range of graph-structured data. (ii) Feature Heterogeneity. Graphs exhibit substantial heterogeneity in their node and edge features, which can span categorical attributes, continuous numerical data, and multi-modal content. Furthermore, the dimensionality and semantics of these features often vary dramatically across different graph domains. For instance, a social interaction graph may include textual content and demographic information associated with its nodes, while a molecular graph may feature atomic compositions and bond types. Effectively handling this feature heterogeneity is crucial for building a versatile graph model capable of generalizing across diverse graph domains. (iii) Fast Adaptation for Broad Applicability. A key capability for effective graph foundation models is the ability to efficiently adapt to new graph dataset and domains. Rather than requiring extensive retraining or fine-tuning, the ideal model should be able to   quickly adjust its parameters and learning strategies to handle the structural and distributional characteristics of previously unseen graph datasets. By seamlessly generalizing and performing well across a diverse range of real-world scenarios -from user behavior graphs to transportation networks and biological systems -these adaptable models can unlock transformative insights across an everexpanding universe of graph-structured data. (iv) Scaling Laws for Transformative Graph Capabilities. A key characteristic of successful foundation models in domains like CV <ref type="bibr" target="#b4">[5]</ref> and NLP <ref type="bibr" target="#b20">[21]</ref> is their ability to exhibit scaling laws -where performance systematically improves as the model size or training dataset increases. By harnessing this emergent scaling phenomenon, graph foundation models can unlock unprecedented levels of capability and generalization, far surpassing the limitations of fixed-capacity architectures. As the size of graph datasets and model complexity grow, these scaling-aware designs can continue delivering transformative performance gains.</p><p>The Presented Work. To tackle the above challenges, our Any-Graph model is built upon a Mixture-of-Experts (MoE) architecture, which allows for effective handling of both the in-domain and cross-domain distribution shift in structure-level and feature-level heterogeneity. The proposed graph MoE paradigm empowers Any-Graph to learn a diverse ensemble of graph experts, each tailored to specific structural characteristics. This enables the model to effectively manage the distribution shift in graph topologies, ranging from homogeneous to highly skewed degree distributions, as well as handle graphs with varying levels of complexity. Furthermore, the MoE architecture of AnyGraph facilitates fast adaptation of the graph model. Rather than relying on a single, fixed-capacity model, the Graph MoE learns an ensemble of specialized expert networks, each tailored to capture distinct structural and feature-level characteristics of graph data. The lightweight graph expert routing mechanism allows AnyGraph to quickly identify and activate the most relevant experts for a given input graph, without requiring extensive retraining or fine-tuning across the entire model. The key findings of this work can be summarized as:</p><p>• Methodology Design Motivations of AnyGraph. Current large graph models <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref> often struggle when faced with the substantial heterogeneity found in real-world graph data. This is especially challenging when it comes to feature-level heterogeneity. These fixed-capacity models may encounter interference between different types of graph datasets, and can sometimes overfit to new data, leading to catastrophic forgetting.</p><p>To address these challenges, the proposed Mixture-of-Experts (MoE) architecture for graph models was designed with a focus on adaptability. This new paradigm empowers the model to flexibly adjust to the nuances of diverse graph datasets, dynamically selecting the most appropriate experts to learn distinct patterns. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>Graph-Structured Data. A graph G consists of a set of nodes V = {𝑣 𝑖 } and a set of edges E = {(𝑣 𝑖 , 𝑣 𝑗 )}. In many cases, each node 𝑣 𝑖 is associated with a feature vector f 𝑖 ∈ R 𝑑 0 . To efficiently utilize such graph-structured data, the link information is typically recorded using an adjacency matrix</p><formula xml:id="formula_0">A ∈ R | V | × | V | . Each element</formula><p>𝑎 𝑖,𝑗 of A is either 1 or 0, inddicating whether there is an edge from node 𝑣 𝑖 to 𝑣 𝑗 . Additionally, the feature vectors of the nodes are usually represented by a feature matrix F ∈ R | V | ×𝑑 0 , where each row corresponds to a node's feature vector. The primary goal of learning from such graph-structured data is to generate embeddings for the graph elements, typically nodes, that effectively capture both the structural and feature-based information of the graph. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Foundation Models (GFMs</head><formula xml:id="formula_1">𝑓 ,L ∑︁ G 𝑡 C (𝑓 Θ (G 𝑡 ), Y 𝑡 ) , Θ = arg min Θ ∑︁ G 𝑠 L (𝑓 Θ (G 𝑠 ), Y 𝑠 ) (1)</formula><p>The above formulation reveals that the key to building graph foundation models are: i) the model architecture design (𝑓 ), which must have the capacity to encode diverse feature spaces and structural patterns, and ii) the model training process (L), which must effectively traverse such diverse data to find an optimal solution Θ for the model 𝑓 . In light of this, our AnyGraph employs a mixture-ofexperts architecture with an automated expert routing method, to seamlessly integrate powerful prediction models for highly diverse graph data. AnyGraph is extensively trained on graphs from various applications using multiple featuring methods, with a graph augmentation technique to further enhance data diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>The proposed AnyGraph framework aims to address both crossdomain and in-domain heterogeneity in graph structures and node features, while enabling fast adaptation to new data. The overall framework of AnyGraph is depicted in Fig. <ref type="figure">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MoE Architecture of AnyGraph</head><formula xml:id="formula_2">ŷ𝑖,𝑗 = ê⊤ 𝑖 ê𝑗 , Ê = 𝑓 Θ 𝑘 (G), 𝑘 = 𝜓 (G)<label>(2)</label></formula><p>where each expert model 𝑓 Θ 𝑘 can be viewed as a projection from the graph space to a node embedding space with uniquely trained parameters Θ 𝑘 . And ŷ𝑖,𝑗 represents the dot-product-based prediction of whether the entity 𝑣 𝑖 should be related to the entity 𝑣 𝑗 . Here, 𝑣 𝑖 and 𝑣 𝑗 could be vanilla graph nodes, class labels, or graph labels.</p><p>3.1.2 Graph Expert Routing Mechanism. Inspired by the effectiveness of graph self-supervised learning tasks <ref type="bibr" target="#b11">[12]</ref>, we propose measuring the competence of expert models on specific graph datasets using the models' self-supervised learning loss values. Specifically, for an input graph G = (V, E), the routing mechanism 𝜓 calculates the dot-product-based relatedness scores for some positive edges (𝑣 𝑐 1 , 𝑣 𝑝 1 ), </p><formula xml:id="formula_3">𝜑 𝑘 = 1 𝑆 • 𝑆 ∑︁ 𝑠=1 𝜎 ( ê⊤ 𝑐 𝑠 ê𝑝 𝑠 -ê⊤ 𝑐 𝑠 ê𝑛 𝑠 )<label>(3)</label></formula><p>where 𝜎 (•) represents the sigmoid activation function, which constrains the competence score to the range of (0, 1). This prevents the few outlier cases where the non-activated score difference is excessively large or small, which could otherwise distort the results.</p><p>Training Frequency Regularization. Although being empirically accurate in measuring models' competence using the aforementioned self-supervised task loss, this routing mechanism tends to result in a winner-takes-all sub-optimal situation. In this scenario, a single model, or very few models, is predominantly selected as the most competent expert and is used to handle almost all input graphs. These expert models generally receive more or better training samples in the early training stages, giving them an advantage over other experts. Consequently, subsequent training samples are also mostly assigned to them due to their performance advantages, ultimately causing other experts to remain largely untrained. This situation contradicts our motivation of using different expert models to learn different subsets of graph modeling knowledge. To address this, we propose a training frequency regularization approach that recalibrates the competence score as follows:</p><formula xml:id="formula_4">𝜑 ′ 𝑘 = 𝜑 𝑘 • (1 - 𝑚 𝑘 𝑘 ′ 𝑚 𝑘 ′ ) • 𝜌 + 1.0 - 𝜌 2<label>(4)</label></formula><p>where 𝜑 ′ 𝑘 represents the recalibrated routing score for the 𝑘-th expert model 𝑓 Θ 𝑘 , based on the number of previously assigned training steps 𝑚 𝑘 for 𝑘 = 1, • • • , 𝐾. The notation 𝜌 refers to a hyperparameter for the recalibration scale. A larger 𝜌 results in a greater adjustment to the competence score 𝜑 𝑘 . With this additional step, the expert routing mechanism will assign more training instances to the less trained expert models, thereby preventing the aforementioned winner-takes-all situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Fast Adaptation Capabilities of AnyGraph.</head><p>With the aforementioned MoE architecture and routing mechanism, the training and inference process of AnyGraph is conducted by only one expert model. This approach consumes only 1/𝐾 of the computational and memory resources required for predictions and optimization, compared to other non-MoE graph foundation models based on complex networks like transformers. This endows AnyGraph with the advantage of fast adaptation when dealing with new datasets. process as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Adaptive and Efficient Graph Experts</head><formula xml:id="formula_5">U A , Λ A , V A = SVD( Ã) U F , Λ F , V F = SVD(F) E 0 =LayerNorm U A √︁ Λ A + V A √︁ Λ A + Flip(U F √︁ Λ F )<label>(5)</label></formula><p>Here,</p><formula xml:id="formula_6">U A , U A ∈ R | V | ×𝑑 and U F ∈ R | V | ×𝑑 , V F ∈ R 𝑑 0 ×𝑑</formula><p>refer to the 𝑑-dimensional features obtained through SVD of the Laplaciannormalized adjacency matrix Ã <ref type="bibr" target="#b13">[14]</ref> and the node feature matrix F, respectively. If the dimensionality of Ã or F is less than 𝑑, SVD uses a smaller rank 𝑑 ′ equal to the smallest dimensionality of Ã/F, and the remaining dimensions are padded with zeros up to 𝑑.</p><p>Due to the nature of SVD, the dimensions of these features (U * , V * ) are ranked from the most important to the least important, corresponding to the descending eigenvalues in the diagonal matrices Λ A and Λ F . In light of this characteristic, we propose to better preserve the most important feature dimensions for both Ã and F. In particular, the function Flip(•) reverses the 𝑑 dimensions of each row for the SVD features of F, such that the important features of Ã are aligned with the less important features of F, and vice versa.</p><p>High-order Connectivity Injection. A non-trainable layer normalization LayerNorm(•) is applied for numerical stability. The initialized embeddings, denoted as E 0 ∈ R | V | ×𝑑 , have consistent representation dimensionality and relatively stable semantics across datasets. To better preserve the multi-hop connection information into the initial embeddings, AnyGraph adopts a simplified GCN without parameters <ref type="bibr" target="#b27">[28]</ref> for E 0 as follows:</p><formula xml:id="formula_7">E 1 = 𝐿 ∑︁ 𝑙=1 E (𝑙 ) 0 , E (𝑙 ) 0 = Ã • E (𝑙 -1) 0 , E (0) 0 = E 0 (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Efficient and Strong</head><p>Feature Encoder. To achieve efficiency while retaining the capacity to encode graph features, our graph experts are configured by deep multi-layer perceptron (MLP) networks. Specifically, the final node embeddings given by an expert model is calculated iteratively as follows:</p><formula xml:id="formula_8">Ē(𝑙+1) = LayerNorm Dropout ReLU( Ē(𝑙 ) W + b) + Ē(𝑙 )<label>(7)</label></formula><p>The final embeddings are denoted as Ê = Ē(𝐿 ′ ) ∈ R | V | ×𝑑 , where 𝐿 ′ represents the number of fully-connected layers. And Ē(0) is initialized by the aforementioned embeddings E 1 . Each layer of our MLP module comprises a linear transformation W ∈ R 𝑑 ×𝑑 and bias b ∈ R 𝑑 , followed by a ReLU non-linear activation, a dropout layer, a residual connection, and layer normalization.</p><p>Multiple Simple Experts as Strong Encoder. It is worth noting that each graph expert in AnyGraph adopts a very simple learnable network, foregoing the capacity to mine complex hidden relations like those in heavy graph neural networks such as GATs <ref type="bibr" target="#b24">[25]</ref> and GraphTransformers <ref type="bibr" target="#b9">[10]</ref>. This is because AnyGraph employs a MoE architecture, where each expert is expected to handle only a subdomain of all graph data through simple feature transformations. Therefore, no complex models are needed to accommodate different types of graphs within a single network. Compared to other graph foundation models that rely on a single heavy network, this approach further accelerates the training and inference processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Efficient Cross-domain Model Training</head><p>To maximize the cross-graph generalizability of AnyGraph, the training samples from different datasets are mixed together and randomly shuffled for model training. Each batch of training samples contains the following information:</p><formula xml:id="formula_9">S = {(𝑣 𝑐 𝑏 , 𝑣 𝑝 𝑏 )|𝑏 ∈ 𝐵} ⊂ E G 𝑠 , E 1 = InitialEmbed(G 𝑠 ), 𝑓 Θ 𝑘 where 𝑘 = 𝜓 (G 𝑠 ) (8)</formula><p>Inspired by the effectiveness of link-wise graph pre-training tasks <ref type="bibr" target="#b11">[12]</ref>, we utilize link prediction as the training task. Here, (𝑣 𝑐 𝑏 , 𝑣 𝑝 𝑏 ) denotes the positive edges for link prediction, and 𝐵 denotes the batch size. </p><formula xml:id="formula_10">L = ∑︁ S ∑︁ 𝑏 ∈𝐵 - 1 𝐵 log exp( ŷ𝑐 𝑏 ,𝑝 𝑏 -ŷmax ) 𝑣 𝑛 ∈ V G𝑠 exp( ŷ𝑐 𝑏 ,𝑛 -ŷmax )<label>(9)</label></formula><p>This training objective maximizes the prediction scores for positive samples (𝑣 𝑐 𝑏 , 𝑣 𝑝 𝑏 ) and minimizes the predictions for all possible node pairs between 𝑣 𝑐 𝑏 and all nodes 𝑣 𝑛 . To avoid numerical instability, we employ a technique where the maximum prediction score of the batch, ŷmax , is subtracted from all prediction scores. For the initial graph embeddings, we periodically reconduct the SVD and simplified GCN processes after a certain number of training steps. This helps generate different embedding spaces for the same data, thereby greatly improving the generalizability of AnyGraph regarding representation heterogeneity <ref type="bibr" target="#b15">[16]</ref>. To prevent this process from consuming excessive computational time, we propose adopting different augmentation frequencies adaptive to the size of different datasets. Specifically, each dataset undergoes this representation augmentation after |E |/(10𝐵) training steps.</p><p>For the graph routing results, we also periodically recalculate the recalibrated competence scores. Specifically, the positive sample pairs (𝑣 𝑐 𝑠 , 𝑣 𝑝 𝑠 ) for 𝑠 = 1, • • • , 𝑆, as well as the negative samples 𝑣 𝑛 𝑠 , are randomly sampled. This essentially performs structure augmentation by using a random subset to evaluate the performance of graph experts on the input graph, thereby enhancing the model's robustness against structural noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Complexity Analysis.</head><p>The training and inference process of AnyGraph is conducted by only one expert model, which has a complexity of O (𝐵 ×𝑑 2 ×𝐿 ′ ) for each batch. Since we preprocess the initial embeddings and the expert routing, these two processes do not increase the batch-wise computational complexity. As a result, the complexity of the forward and backward steps for AnyGraph is much lower than that of other graph foundation models that involve complex GNNs and graph transformers. Additionally, the expert routing performs</p><formula xml:id="formula_11">O G 𝑠 |E 𝑠 | × 𝑑 × 𝐾 + G 𝑠 |V 𝑠 | × 𝑑 2 × 𝐿 ′ × 𝐾 computations,</formula><p>where the latter term empirically has a larger scale compared to the former term. This dominant term is similar to a simple GCN network of a comparable model size. Overall, Any-Graph is more efficient than existing methods in both training and inference, and the additional computations for routing have a complexity comparable to simple GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Our experiments aim to answer the following Research Questions: • RQ1: How does the zero-shot prediction performance of Any-Graph compare to different baseline methods? • RQ2: How do AnyGraph's various modules impact its overall performance with the contribution of each component? We set up different dataset groups and conduct cross-dataset evaluations on these groups. Specifically, all datasets are divided into two cross-domain groups, Link1 and Link2, which have a similar number of total edges and a similar number of domainspecific edges. Specifically, the Link1 and Link2 groups contain 15 and 18 datasets, respectively. For the node classification task, we use 5 datasets gathered from e-commerce and academic information scenarios. Additionally, we have three domain-specific groups: Ecommerce, Academic, and Others. The Others group is primarily composed of biological networks, combined with other small domains that have fewer datasets. See Appendix A.1 for more information of our experimental datasets.</p><p>4.1.2 Experimental Settings. We follow previous works <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14]</ref> for dataset splitting and evaluation metrics. Our AnyGraph model and the graph foundation models are evaluated on a cross-graph zero-shot prediction task. For baselines that cannot handle crossdataset transfer, we evaluate their few-shot performance. Details of the evaluation protocols are provided in Appendix A.2. The Hyperparameter Settings of AnyGraph are provided in Appendix A.3. The compared Baseline Methods are introduced in Appendix A.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">AnyGraph's Zero-Shot Prediction (RQ1)</head><p>To assess the zero-shot prediction capabilities of the AnyGraph model, we conducted an extensive evaluation across 38 graph datasets from various domains. We independently trained two versions of the AnyGraph model -one on the Link1 dataset and the other on the Link2 dataset. Each trained model was then used to make zero-shot predictions on datasets it was not originally trained with. It is important to note that the Link1 and Link2 datasets do not share the same feature spaces or sources of data collection, which adds to the complexity and challenges of the zero-shot evaluation. We also compare our AnyGraph with existing graph foundation models. And in this comparison we add another AnyGraph-F version, which removes the utilization of node features. The outcomes of this evaluation are detailed in Table <ref type="table" target="#tab_7">1</ref> and Table <ref type="table" target="#tab_8">2</ref>, and our key observations are listed as follows:</p><p>i) Superior Generalizability across Diverse Datasets. • Superior Prediction Accuracy. Compared to the few-shot capabilities of existing GNN models, pre-training techniques, and foundation models, AnyGraph demonstrates exceptional zero-shot prediction accuracy across various domains. This superior performance spans both link prediction and node classification tasks. • Effectively Handling Heterogeneity. The enhanced generalizability can be attributed to the effective handling of structure-level and feature-level data heterogeneity through unified structure and feature representations in the expert models. This approach enables AnyGraph to develop comprehensive modeling functions that are universally applicable across different graph data scenarios. • Comprehensive Training. Additionally, the extensive training regimen, which incorporates a variety of large-scale datasets, equips AnyGraph with a deep and broad expertise in graph modeling and prediction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Scaling Law of AnyGraph Framework (RQ2)</head><p>In this section, we explore the applicability of the scaling law to AnyGraph. We conduct experiments using 18 different versions of AnyGraph, each differing in model size and quantity of training data. Specific configurations of these variants are discussed in Appendix A.5. The evaluation results are depicted in Figure <ref type="figure" target="#fig_8">3</ref>, which includes overall and domain-specific performance, as well as zero-shot and full-shot outcomes. Our key findings are as follows:</p><p>i) Generalizability of AnyGraph Follows the Scaling Law.</p><p>As the model size and the volume of training data increase, we notice a saturation point in AnyGraph's full-shot performance. In contrast, the zero-shot prediction accuracy continues to improve. This pattern supports the scaling law of graph foundation models, illustrating that scaling up can significantly enhance the capabilities of graph models. Two key factors contribute to this phenomenon:</p><p>• Task Difficulty. The saturation in full-shot performance is partly because the evaluation tasks might not be challenging enough.</p><p>In-domain generalization can be more straightforward, leading to a plateau in performance improvements. This insight into the scaling law for graph data encourages further exploration of larger models on more complex graph learning tasks. • MoE Architecture. The integration of the Mixture of Experts (MoE) architecture allows AnyGraph to effectively manage and utilize a broader spectrum of knowledge, particularly in this zeroshot scenario characterized by significant distribution disparities. ii) Emergent Abilities of AnyGraph. The overall zero-shot performance curve illustrates that as the model size increases, the performance sometimes experiences periodic stagnation. With further increments in parameters, AnyGraph's performance undergoes a sudden significant improvement. This phenomenon indicates the emergent abilities of AnyGraph, demonstrating the effectiveness of scaling up in enhancing its generalization capabilities.</p><p>iii) Insufficient training data may bring bias. In the initial stages of increasing the training data, the introduction of new datasets might negatively impact performance due to their differences from the test graphs. However, this issue can be mitigated by further expanding the training data. By providing the model with a more comprehensive set of training samples, it helps prevent overfitting and reduces bias stemming from dataset disparities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study (RQ3)</head><p>This section evaluates the effectiveness of AnyGraph's sub-modules by comparing ablated variants in terms of their zero-shot and fullshot performance across both cross-domain datasets and domainspecific datasets (specifically Academic data). The results are in Figure <ref type="figure" target="#fig_10">4</ref>. We make the following observations:</p><p>• MoE Significantly Enhances Zero-Shot Performance. The -MoE variant, which employs a single expert model without the MoE architecture, demonstrates decent performance on datasets on which it was trained, as shown in parts (b) and (c). However, this variant exhibits a substantial decline in zero-shot prediction capabilities. This underscores the critical role of the MoE architecture in enhancing AnyGraph's generalization abilities. The use of multiple expert models significantly expands AnyGraph's modeling capacity, effectively managing the large disparities between various domains using multiple seperated models. • Feature Modeling is Crucial in AnyGraph. In the -Feat variant, node features are omitted, leading to the most significant degradation in both zero-shot and full-shot performance. This underscores the effectiveness of AnyGraph's unified structure         </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Investigation on Expert Routing (RQ4)</head><p>This section delves into the expert routing mechanism of AnyGraph. Figure <ref type="figure" target="#fig_12">5</ref> displays the competence scores of various expert models for the input datasets, as determined by AnyGraph's routing algorithm based on the self-supervised loss. The figure illustrates that datasets sharing common characteristics-such as source of collection or feature construction method-are often routed to the same expert models by AnyGraph. For instance, datasets like arxiv-ta, Photo, GoodReads, and Fitness, which utilize a common text-embeddingbased feature space, are assigned to highly similar experts (expert 0, 2, 4, 5). Additionally, ML1M and ML-10M, both sourced from the movie-rating platform Movielens, are predominantly associated with expert 1. It is also notable that this routing pattern extends to zero-shot datasets, as shown on the right part of Figure <ref type="figure" target="#fig_12">5</ref>. Here, YelpT, SteamT, and AmazonT, which share the same feature space, are assigned to very similar expert models. This outcome underscores the efficacy of AnyGraph's routing mechanism in identifying the appropriate expert models for various datasets, and also showcases its explainability in revealing graph-wise relatedness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Efficiency Study (RQ5)</head><p>Tuning Curve Comparison. To evaluate the efficiency of Any-Graph, we compare its fine-tuning process with that of GraphCL and the training from scratch process of a GCN model. As depicted in Figure <ref type="figure" target="#fig_15">6</ref>, when fine-tuned on a new dataset, the pre-trained Any-Graph rapidly achieves a high performance saturation point. In    some instances, such as with the PPA dataset, GraphCL and the end-to-end trained GCN struggle to attain comparable performance levels. This advantage is based on i) the strong cross-domain generalization capabilities of AnyGraph, which bring a high starting point for the new dataset, and ii) the efficiency of AnyGraph's MoE architecture, which requires only one MLP network for efficient but effective modeling and parameter tuning. In addition, it is observed that pre-training GraphCL does not consistently benefit its fine-tuning on new datasets, as evidenced by GraphCL's underperformance relative to GCN in Figure <ref type="figure" target="#fig_15">6(b)</ref>. This should be ascribed to the large distribution gap between the pre-training data Link2 and the test data PPA.</p><p>Training Time Comparison. To evaluate the efficiency of the models under consideration, we compared the training times of the three models. As indicated in Table <ref type="table" target="#tab_9">3</ref>, AnyGraph, despite having significantly more parameters, has training times that are comparable to, or even less than, the other two models. This underscores the efficiency of our model design, and demonstrates the efficiency of AnyGraph to adapt to new data through model tuning.</p><p>Specifically, AnyGraph avoids the cumbersome process of fullgraph propagation at each training step. Instead, it utilizes structureaware embeddings derived through a non-trainable pre-processing method. This approach significantly reduces both the time and memory requirements for AnyGraph. Furthermore, the MoE architecture equips AnyGraph with the capability to use only 1/𝐾 of the computational resources for most prediction and optimization processes, thereby greatly reducing overall computational costs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Works</head><p>Graph Neural Models. Graph learning has garnered significant interest for its broad applicability across various fields such as user behavior modeling, social analysis, and studies in biology and chemistry <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8]</ref>. Graph neural networks (GNNs) learn node representation vectors for downstream tasks like node classification and link prediction. The core mechanism involves iterative message passing, refining node embeddings to capture both node-specific information and higher-order topological structures. This process ensures that the final node embeddings effectively encapsulate both node-specific information and higher-order topological structures. Notable techniques include Graph Convolutional Networks (GCNs) <ref type="bibr" target="#b10">[11]</ref>, Graph Attention Networks (GATs) <ref type="bibr" target="#b0">[1]</ref>, Graph Isomorphism Network (GIN) <ref type="bibr" target="#b32">[33]</ref>, and Graph Transformer <ref type="bibr" target="#b9">[10]</ref>, which improves the encoding function for better graph modeling. Despite these advancements, these methods still require high-quality training data and often struggle with generalization capabilities.</p><p>Self-Supervised Graph Learning. Given the challenges with the generalizability of GNNs, considerable research efforts <ref type="bibr" target="#b31">[32]</ref> have focused on enhancing GNNs through self-supervised learning objectives, aiming to capture invariant graph features. Specifically, GraphCL <ref type="bibr" target="#b35">[36]</ref> introduced a contrastive pre-training approach for graph data, designed to learn authentic graph characteristics that are robust to structural and feature perturbations. Building on this, JOAO <ref type="bibr" target="#b34">[35]</ref> and GCA <ref type="bibr" target="#b38">[39]</ref> have developed adaptive augmentation strategies for self-supervised tasks, effectively mitigating the adverse effects of random augmentations. Subsequent works have sought to quickly adapt these pre-trained models to downstream tasks and evolving graph data, as demonstrated by GPF <ref type="bibr" target="#b5">[6]</ref> and GraphPrompt <ref type="bibr" target="#b18">[19]</ref>. Despite these advancements, the generalizability of these methods remains confined to graph data with similar structural patterns and feature spaces, thus not addressing the crossdomain generalization challenges highlighted in this paper.</p><p>Large-scale Graph Pre-training. Recent advances in graph modeling have seen efforts to pre-train large-scale graph models across multiple datasets to improve their generalization abilities, drawing inspiration from the strong generalization capabilities of large language models (LLMs) <ref type="bibr" target="#b29">[30]</ref>. For instance, OFA <ref type="bibr" target="#b16">[17]</ref> and ZeroG <ref type="bibr" target="#b15">[16]</ref> utilize text embeddings to standardize the feature spaces across various graph datasets and tasks, facilitating cross-dataset training of graph models. Models like InstructGLM <ref type="bibr" target="#b33">[34]</ref> GraphGPT <ref type="bibr" target="#b22">[23]</ref> and LLaGA <ref type="bibr" target="#b3">[4]</ref> synchronize graph representation spaces with the hidden spaces of LLMs, thus enabling the application of general LLMs for graph prediction tasks. Furthermore, HiGPT <ref type="bibr" target="#b23">[24]</ref> expands the capabilities of LLMs to accommodate heterogeneous graph data.</p><p>Despite these advancements, most generalized graph models require substantial access to and integration of text features, which confines their use primarily to text-abundant environments such as academic networks. Additionally, these methods are typically trained within specific application realms, failing to address the significant variances between datasets from diverse domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, the presented AnyGraph framework, an effective and efficient graph foundation model designed to address the multifaceted challenges of structure and feature heterogeneity across diverse graph datasets. AnyGraph's innovative Mixture-of-Experts (MoE) architecture, coupled with its dynamic expert routing mechanism, positions it at the state-of-the-art of cross-domain generalization capabilities. Extensive experiments on 38 varied graph datasets have not only underscored AnyGraph's superior zero-shot learning performance but also its robustness to distribution shifts and its adherence to scaling laws, thereby enhancing its predictive accuracy with increased model size and data volume. The model's efficiency in training and inference, validated through comparison with existing methods, further cements its practical applicability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix A.1 Experimental Datasets</head><p>We utilize a total of 38 graph datasets across various domains. The entire dataset contains 14,437,372 nodes, and 199,265,688 edges. The dataset specifics are detailed below: E-commerce Datasets. This category includes 15 datasets from various e-commerce contexts such as user rating platforms and online retail services. These datasets vary in terms of the presence and type of node features. For instance, datasets such as Amazon-book, Yelp2018, Gowalla, Yelp-text, Amazon-text, Steam-text, Goodreads, Amazon-Fitness, Amazon-Photo, Movielens-1M, Movielens-10M, Products-home, Products-tech, Home-node, Tech-node are included. Notably, Amazon-text, Steam-text, and Yelp-text utilize the same method for feature generation, while Fitness, Photo, and Goodreads employ a different consistent method. Academic Network Datasets. We use 13 datasets focused on academic networks, which include citation and collaboration relations among scholars and papers. These datasets represent various research fields and employ diverse feature generation methods, such as NLP embeddings, bag-of-words, and different versions of large language models. The specific datasets are Cora, Pubmed, Arxiv, Cora-link, Pubmed-link, Citeseer, CS, Arxiv-link, Arxiv-t (with features derived using an alternative method), Citation-2019, Citation-20Century, OGB-Collab. Biological Information Networks. Our collection includes 6 datasets related to biological entities like proteins, drugs, and diseases. This category features networks such as OGB-DDI, OGB-PPA and four protein relation networks for different species, denoted as Proteins-0, Proteins-1, Proteins-2, Proteins-3. Other Datasets. In addition to the categories mentioned above, we include 5 datasets from various other fields: an email network Email-Enron, a website network Web-Stanford, a road network dataset RoadNet-PA, a P2P web network dataset P2P-Gnutella06, and a trust network dataset Soc-Epinions1. Dataset Groups. For conveinience of performance evaluation, we split the many datasets using different grouping methods. Firstly, two big data groups Link1 and Link2 are made using all the link prediction datasets. Notably, datasets from the same source of collection, such as Movielens-1M and Movielens-10M, or uses the same method to generate features, such as Fitness, and Photo, are put into the same group, to avoid information leakage when evaluating zero-shot performance on the other group. Apart from these two datasets, we also conduct evaluations on domain-specific groups, including E-commerce, Acadmic, and Others. Specifically, these data groups contain the following datasets, respectively: • Link1: Products-tech, Yelp2018, Yelp-textfeat, Products-home, Steam-text, Amazon-text, Amazon-book, Citation-2019, Citation-20Century, Pubmed-link, Citeseer, OGB-PPA, P2P-Gnutella06, Soc-Epinions1, Email-Enron. • Link2: Photo, Goodreads, Fitness, Movielens-1M, Movielens10M, Gowalla, Arxiv, Arxiv-t, Cora, CS, OGB-Collab, Proteins-0, Proteins-1, Proteins-2, Proteins-3, OGB-DDI, Web-Stanford, RoadNet-PA. • Ecommerce and Academic: These two datasets contain all the domain-specific datasets as mentioned above.</p><p>• Others: This group contains all the biological datasets, and other datasets including Email-Enron, Web-Stanford, RroadNet-PA, P2P-Gnutella06, Soc-Epinions1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Evaluation Protocols</head><p>All datasets used in this study are sourced from previous research as referenced <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b22">23]</ref>. We adhere to the original data splits from these sources to delineate our training and testing sets. Given that many baseline methods are not equipped to manage zero-shot prediction across datasets, we instead assess their few-shot capabilities. This allows for a comparative analysis against the zero-shot performance of AnyGraph. We employ specific evaluation settings tailored to each method, detailed as follows:</p><p>• Zero-shot Setting for AnyGraph, GraphGPT, and Open-Graph. In our study, AnyGraph and two comparative graph foundation models, GraphGPT and OpenGraph, undergo evaluations for zero-shot prediction capabilities. We pre-train two instances of AnyGraph using Link1 and Link2 datasets. The model pre-trained on Link1 is then tested for zero-shot performance on the Link2 group datasets, and vice versa. Results labeled as "zero-shot" for AnyGraph are derived using this cross-evaluation method. Conversely, results marked as "full-shot" pertain to supervised learning outcomes, where, for example, the model trained on Link1 is tested on the test sets of Link1 group datasets. For GraphGPT and OpenGraph, we utilize the models as released in their respective original studies, which were pre-trained on specified datasets. • Zero-shot Node Classification for AnyGraph. Drawing from insights in prior research <ref type="bibr" target="#b21">[22]</ref>, our approach to zero-shot node classification involves a novel method where label classes are represented as distinct nodes. We then connect existing nodes that have training labels directly to these new class nodes. This technique eliminates the need for learning specific parameters for each class within the zero-shot learning framework, streamlining the process. We have integrated this innovative approach into baseline methods as well, enhancing their capability to handle unseen node labels effectively. • Few-shot Training for GIN and GAT. The GIN and GAT models, employed as end-to-end training baselines, undergo training from scratch on few-shot subsets of the evaluation datasets. This approach is necessary because these models are not well-suited for cross-dataset transfer, particularly when dealing with datasets that have varying feature dimensionalities. • Pre-training and Few-shot Tuning for GraphCL, GPF and GraphPrompt. These category of baselien methods follow the pre-training-and-fine-tuning mode. In our evaluations, they are firstly pre-trained using the same pre-training datasets as our AnyGraph. Then, they experience an additional fine-tuning process using the few-shot subsets of the evaluation datasets. Evaluation Metrics. For link prediction, we follow previous works <ref type="bibr" target="#b8">[9]</ref> and utilize Recall@20 and NDCG@20 as the evaluation metrics. Note that we typically use the summary results of the evaluation results across multiple datasets. Results for fifferent datasets are averaged according to their number of test samples. For the node classification task, we employ the widely-used Accuracy and Macro-F1 score as our metrics <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b22">23]</ref>. The frequency regularization of our routing mechanism is set with an adjustment range of 𝜌 = 0.2. The SVD decomposition is performed using 2 iterations. For structural and feature augmentation, each dataset is reprojected after using 1/10 of its samples for optimization. A minimum of 100 training steps should be executed for each dataset before its initial representations are reprojected. The reassignment of experts occurs after all training datasets have undergone one cycle of re-projection. The baseline methods are evaluated using theeir original code or released model. We closely follow the original code to adapt to our experiments. Grid search is conducted to search for the best hyperparameter settings for each baseline method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Baseline Methods</head><p>This section provides detailed descriptions of the baseline models used in our analysis. We employ seven different baseline models across four distinct categories. Training-from-scratch Graph Neural Networks.</p><p>• GAT <ref type="bibr" target="#b24">[25]</ref>. Graph Attention Networks (GAT) leverage an attention mechanism to dynamically weight node-to-node connections, enhancing the model's ability to adaptively propagate and aggregate information across the graph. • GIN <ref type="bibr" target="#b32">[33]</ref>. The Graph Isomorphism Network (GIN) significantly boosts the expressive power of Graph Neural Networks by introducing a unique graph encoding technique aimed at effectively distinguishing between non-isomorphic graphs.</p><p>Graph Pre-training Models.</p><p>• GraphCL <ref type="bibr" target="#b38">[39]</ref>. It enhances the pre-training of graph models via self-discriminative contrastive learning, which is applied to learned node embeddings. The method employs various graph augmentation techniques such as node dropping, edge permutation, random walks, and feature masking to improve robustness. Graph Prompt Tuning Methods.</p><p>• GraphPrompt <ref type="bibr" target="#b18">[19]</ref>. GraphPrompt proposes a unified approach that integrates pre-training and prompt tuning for graph models. It features a learnable prompt layer designed to automatically extract crucial information from the pre-trained model to enhance performance on downstream tasks. For the increase of training data, we begin with a subset of Link2 data including Cora and CS. The next version additionally includes Photo. The thir one includes ML1M. The fourth one includes Gowalla. The fifth one additionally include Arxiv and Arxiv-t. The sixth one adds the following datasets: collab, ddi, Yelp2018, Fitness, proteins-spec1, web-Stanford, proteins-spec3. The seventh one is trained with proteins-2, roadNet-PA, and Fitness additionally. And the final one is trained with all datasets from Link2.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: AnyGraph's generalizability and scaling law reveals its exceptional capabilities. Compared to baseline methods, the superior performance of AnyGraph can be observed in its exceptional cross-domain generalization ability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3. 2 . 1 Figure 2 :</head><label>212</label><figDesc>Figure 2: The proposed graph Mixture-of-Experts (MoE) paradigm enables AnyGraph to learn a diverse ensemble of graph experts, each tailored to specific structural characteristics. The lightweight expert routing mechanism allows AnyGraph to quickly identify and activate the most relevant experts for a given input graph, without extensive retraining or fine-tuning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Cross-domain performance on Link1 (zero-shot) and Link2 (full-shot).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Performance on academic data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Performance on ecommerce data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Performance on others.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Zero-shot and full-shot performance w.r.t. the number of model parameters and the amount of training samples.</figDesc><graphic coords="7,355.23,297.57,78.83,78.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Full-shot performance on Academic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Impact of different sub-modules on the zero-shot and full-shot prediction capabilities of AnyGraph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Competence score between datasets and expert models, given by the routing mechanism of AnyGraph.</figDesc><graphic coords="7,465.58,297.57,78.83,78.83" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Performance on Citation-2019.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Performance v.s. training/tuning steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>• Stronger Gernealiation Capacities of AnyGraph. Through our extensive experiments, the proposed AnyGraph model with the graph MoE framework has demonstrated strong generalization capacities across a wide range of graph tasks and domains. The experimental results showcase the AnyGraph's ability to outperform existing graph models in terms of both predictive performance and robustness to distribution shift. • Fast Adapability of AnyGraph. Our innovative dynamic ex-</figDesc><table /><note><p><p>pert selection mechanism enhances AnyGraph's ability to swiftly adapt to new graph domains. By dynamically routing inputs through relevant experts, AnyGraph can quickly activate the specialized networks best suited for the task. This strong adaptation sets AnyGraph apart from baselines. Evaluation shows its superiority through rapid convergence and exceptional performance, further justifying its cross-domain versatility.</p>• The Scaling Law of AnyGraph. Our experiments reveal that AnyGraph's performance follows the scaling law, where the model continues to improve as model size and training data increase. Additionally, AnyGraph exhibits emergent abilities, where its generalization capabilities see sudden significant improvements with further scaling. This critical scaling law property has been largely overlooked in prior investigations, but it underscores the immense value that AnyGraph derives from its scaling-driven enhancements to generalization performance.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>𝑠 , where each graph G 𝑠 is associated with a label set Y 𝑠 . Similarly, the set of test graphs is denoted as T = G 𝑡 , with labels Y 𝑡 . With a differentiable training objective L and an evaluation criterion C to measure the prediction accuracy of downstream tasks, building a graph foundation model 𝑓 Θ with trainable parameters Θ can be formalized as follows:</figDesc><table><row><cell>). The essence of GFMs lies in their strong generalization capabilities. Specifically, a graph founda-tion model should be able to handle unseen graph data that exhibits significant discrepancies from its training graph datasets. These discrepancies may include differences in feature spaces, as well as variations in node and edge semantics across datasets. Formally, let's denote the training graphs as S = G arg max</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>• • • , (𝑣 𝑐 𝑆 , 𝑣 𝑝 𝑆 ) ∈ E and analogously calculates the relatedness scores for some sampled negative node pairs (𝑣 𝑐 1 , 𝑣 𝑛 1 ), • • • , (𝑣 𝑐 𝑆 , 𝑣 𝑛 𝑆 ) ∉ E. The following score difference is then calculated as the competence indicator 𝜑 𝑘 for the 𝑘-th expert model regarding the input graph G:</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>To facilitate batch training, each training batch involves only one training graph G 𝑠 . The initial node embeddings E 1 and the most competent expert model 𝑓 Θ 𝑘 are preprocessed in advance to accelerate the training. Specifically, the loss function used by our AnyGraph training is as follows:</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>3.3.1Feature and Structure Augmentation. To further enrich the training data, the training of AnyGraph undergoes periodic reprocessing of, firstly, the initial graph embeddings E 1 , and secondly, the graph routing results. We demonstrate that such reprocessing augments the features and structures of the original graph data, thereby training AnyGraph using more diversified input data.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>• RQ3: How does the model size and the amount of training data influence the performance of AnyGraph? • RQ4: How interpretable is the expert routing mechanism within AnyGraph's graph Mixture-of-Experts (MoE) architecture? • RQ5: How is the scalability and efficiency of AnyGraph compare to fine-tuning methods when adapting to new datasets? relations), academic graphs (e.g. citation and collaboration networks), biological information networks (e.g. relations among drugs and proteins), and other domains like email networks, website networks, trust networks, and road networks.</figDesc><table><row><cell>4.1 Experimental Settings</cell></row></table><note><p><p>4.1.1 Experimental Datasets.</p>To conduct a comprehensive evaluation of the cross-domain generalizability of graph models, we employ a total of 38 graph datasets. These datasets span a wide range of domains, including e-commerce (e.g. user interactions and product-wise</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 1 :</head><label>1</label><figDesc>We evaluate the AnyGraph model (in zero-shot settings) and baseline models (with 5% and 10% training data) on link prediction (Recall@20, NDCG@20), node classification (Accuracy, Macro F1), and graph classification (Accuracy, Macro F1).</figDesc><table><row><cell>Data</cell><cell>Train 5%</cell><cell>GIN Train 10%</cell><cell>Train 5%</cell><cell>GAT Train 10%</cell><cell>Tune 5%</cell><cell>GPF Tune 10%</cell><cell>GraphPrompt Tune 5% Tune 10%</cell><cell>GraphCL Tune 5% Tune 10%</cell><cell>AnyGraph 0-shot</cell></row><row><cell cols="10">Metric Rec NDCG Rec NDCG Rec NDCG Rec NDCG Rec NDCG Rec NDCG Rec NDCG Rec NDCG Rec NDCG Rec NDCG Rec NDCG</cell></row><row><cell cols="10">Link1 6.46 3.06 11.80 5.45 13.52 6.65 13.45 6.78 6.04 2.92 6.80 3.27 4.33 2.24 5.42 3.11 17.23 9.00 20.55 10.76 23.94 12.68</cell></row><row><cell cols="10">Link2 6.72 4.50 21.62 13.41 9.83 5.91 15.30 8.84 7.44 4.25 16.58 9.84 6.06 3.36 6.10 3.62 29.18 17.62 31.42 19.91 46.42 27.21</cell></row><row><cell cols="10">Ecom. 3.36 2.58 13.41 8.06 3.79 2.94 9.64 5.78 7.25 3.84 18.72 10.94 4.90 2.59 6.06 3.36 22.13 13.19 26.05 14.59 26.92 15.05</cell></row><row><cell cols="10">Acad. 10.82 4.70 20.61 9.04 14.95 6.29 11.17 4.67 13.22 5.80 14.83 6.41 6.73 3.05 7.72 3.40 24.86 12.50 28.69 14.31 32.74 15.31</cell></row><row><cell cols="10">Othrs. 6.92 4.46 18.43 11.85 16.34 9.22 16.17 20.88 2.40 2.12 4.51 3.44 2.93 2.36 3.42 2.72 24.54 14.93 24.62 15.90 46.83 28.97</cell></row><row><cell cols="10">Metric Acc MacF1 Acc MacF1 Acc MacF1 Acc MacF1 Acc MacF1 Acc MacF1 Acc MacF1 Acc MacF1 Acc MacF1 Acc MacF1 Acc MacF1</cell></row><row><cell cols="10">Node 20.79 19.46 36.04 30.60 53.76 40.14 54.83 41.61 12.77 11.45 16.29 16.00 18.01 20.59 23.15 22.89 43.70 33.72 48.75 36.15 64.31 43.24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 2 :</head><label>2</label><figDesc>Comparing AnyGraph framework to existing graph foundation models in zero-shot prediction capabilities.</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="2">GraphGPT</cell><cell></cell><cell>OpenGraph</cell></row><row><cell>Data</cell><cell cols="2">Pubmed</cell><cell></cell><cell>Cora</cell><cell>Ecom. w/o GR</cell></row><row><cell>Metric</cell><cell>Acc</cell><cell>MacF1</cell><cell>Acc</cell><cell cols="2">MacF1 Recall NDCG</cell></row><row><cell>Baseline</cell><cell cols="5">0.1813 0.1272 0.7011 0.6491 0.1444 0.1099</cell></row><row><cell cols="6">AnyGraph-F 0.5852 0.5325 0.7134 0.6003 0.2281 0.1600</cell></row><row><cell>AnyGraph</cell><cell cols="5">0.6088 0.5492 0.7809 0.7591 0.2382 0.1552</cell></row></table><note><p>ii) Limitation of existing pre-training GNNs. • Challenges of Cross-Domain Transfer. Existing pre-training and tuning methods, like GPF, GraphPrompt, and GraphCL, employ self-supervised learning and are pre-trained on half the datasets, then fine-tuned on the remaining datasets using few-shot data. However, this pretraining often fails to yield significant improvements due to substantial distribution disparities across data domains. For instance, datasets may exhibit vastly different link densities or utilize distinct node features, which significantly challenges the transfer of useful knowledge from divergent pre-training datasets during fine-tuning and prediction. • AnyGraph's Robust Adaptability To address this challenge, the AnyGraph model incorporates multiple graph expert models tailored to various sub-domains of graph data. This MoE architecture effectively manages datasets from distinctly different domains, such as e-commerce user behaviors, academic networks, and road networks, demonstrating its robust adaptability.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 3 :</head><label>3</label><figDesc>Training time for each 100 steps on different data.</figDesc><table><row><cell cols="4">Dataset CS ML1M Yelp Email Cite19 roadNet PPA</cell></row><row><cell cols="2">GCN 1.5s 4.2s 6.0s 2.5s 19.2s</cell><cell cols="2">27.8s 101.1s</cell></row><row><cell cols="2">GraphCL 1.1s 4.9s 9.4s 2.8s 43.1s</cell><cell cols="2">57.1s 130.8s</cell></row><row><cell>Ours</cell><cell>1.5s 3.5s 6.1s 3.0s 31.6s</cell><cell>37.3s</cell><cell>41.1s</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4 :</head><label>4</label><figDesc>Statistics of the experimental datasets. Our model, AnyGraph, is implemented using Py-Torch. The optimization process employs the Adam optimizer with a learning rate of 1 × 10 -4 and a training batch size of 4096. We use cross-entropy loss with a sampled negative set<ref type="bibr" target="#b28">[29]</ref>. The learnable parameters of AnyGraph are initialized using the Xavier uniform initializer. Network Configurations. The standard configuration of our AnyGraph includes 512 hidden units and 8 graph expert models. Each expert model comprises 8 fully-connected layers. These layers utilize a ReLU activation function and incorporate a dropout layer with a dropout probability of 0.1. Algorithm Hyperparameters.</figDesc><table><row><cell>Dataset</cell><cell>DDI</cell><cell>Collab</cell><cell>ML1m</cell><cell cols="2">ML10m Amazon-book</cell><cell>PPA</cell><cell>Yelp2018</cell><cell cols="2">Gowalla Cora</cell><cell cols="2">Pubmed Citeseer</cell></row><row><cell># Nodes</cell><cell>4,267</cell><cell>235,868</cell><cell>9,746</cell><cell>80,555</cell><cell>144,242</cell><cell>576,289</cell><cell>69,716</cell><cell>70,839</cell><cell>2,708</cell><cell>19,717</cell><cell>3,327</cell></row><row><cell cols="2"># Edges 1,334,889</cell><cell>1,285,465</cell><cell>920,193</cell><cell>9,200,050</cell><cell>2,984,108</cell><cell>45,495,642</cell><cell>1,561,406</cell><cell cols="2">1,027,370 10,556</cell><cell>88,648</cell><cell>9,104</cell></row><row><cell>𝑑 Feats</cell><cell>0</cell><cell>128</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>58</cell><cell>0</cell><cell>0</cell><cell>1433</cell><cell>500</cell><cell>3703</cell></row><row><cell cols="7">Datasets Proteins-0 Proteins-1 Proteins-2 Proteins-3 Products-home Products-tech</cell><cell>Yelp-t</cell><cell cols="4">Amazon-t Steam-t Goodreads Fitness</cell></row><row><cell># Nodes</cell><cell>25,449</cell><cell>6,568</cell><cell>18,108</cell><cell>13,015</cell><cell>9,790</cell><cell>47,428</cell><cell>22,101</cell><cell cols="4">20,332 28,547 676,084 173,055</cell></row><row><cell cols="2"># Edges 11,660,646</cell><cell>1,845,960</cell><cell>7,418,688</cell><cell>3,962,930</cell><cell>131,843</cell><cell>2,077,241</cell><cell>277,535</cell><cell cols="4">200,860 525,922 8,582,306 1,773,500</cell></row><row><cell>𝑑 Feats</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>100</cell><cell>100</cell><cell>1536</cell><cell>1536</cell><cell>1536</cell><cell>768</cell><cell>768</cell></row><row><cell cols="11">Datasets Soc-Epinions1 Email-Enron Web-Stanford RoadNet-PA P2P-Gnutella06 Citation-2019 Citation-20Century Arxiv Arxiv-t Photo</cell><cell>CS</cell></row><row><cell># Nodes</cell><cell>75,879</cell><cell>36,692</cell><cell>281,903</cell><cell>1,088,092</cell><cell>8,717</cell><cell>765,658</cell><cell>1,016,241</cell><cell cols="2">169,343 169343</cell><cell>48,362</cell><cell>18,333</cell></row><row><cell># Edges</cell><cell>508,837</cell><cell>183,831</cell><cell>2,312,497</cell><cell>1,541,898</cell><cell>31,525</cell><cell>1,917,381</cell><cell>5,565,798</cell><cell cols="4">1,166,243 1,166,243 500,939 163,788</cell></row><row><cell>𝑑 Fets</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>128</cell><cell>128</cell><cell>128</cell><cell>128</cell><cell>768</cell><cell>768</cell><cell>6805</cell></row><row><cell cols="4">A.3 Hyperparameter Settings</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Optimization.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>• GPF<ref type="bibr" target="#b5">[6]</ref>. The Graph Prompt Framework (GPF) is a versatile graph prompt tuning framework compatible with various graph pretraining methods. It offers two variants of a learnable graph prompt layer, tailored to different application needs.A.5 Details of the Scaling Law ExperimentFor the scaling law experiment (RQ2), we elaborate the configurations of the developed instances of AnyGraph. For AnyGraph with different model sizes, we begin with the smallest model which has 64 hidden units, 1 fully-connected layer, and 1 expert model. The subsequent 3 model instances increases in their hidden dimensionality, from 64 to 128, 256, and 512. Then 3 larger models with more fully-connected layers are utilized, respectively containing 2, 4, and 8 MLP layers. Then we have MoE versions of AnyGraph, with 2, 4, and 8 experts, respectively. The final largest instance of AnyGraph has a larger latent dimensionality of 1024.</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How attentive are graph attention networks?</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yahav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sequential recommendation with graph neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="378" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Graph unlearning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Humbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGSAC</title>
		<imprint>
			<biblScope unit="page" from="499" to="513" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Llaga: Large language and graph assistant</title>
		<author>
			<persName><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reproducible scaling laws for contrastive language-image learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cherti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Beaumont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wightman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wortsman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schuhmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jitsev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2818" to="2829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Universal prompt tuning for graph neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Position: Relational deep learning-graph representation learning on relational databases</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Asgn: An active semi-supervised graph neural network for molecular property prediction</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="731" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Lightgcn: Simplifying and powering graph convolution network for recommendation</title>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Heterogeneous graph transformer</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="2704" to="2710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Universal graph convolutional networks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="10654" to="10664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automated self-supervised learning for graphs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Graph structure learning for robust graph neural networks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="66" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Training graph neural networks with 1000 layers</title>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="6437" to="6449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Zerog: Investigating cross-dataset zero-shot transferability in graphs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">One for all: Towards training one graph model for all classification tasks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Graph selfsupervised learning: A survey</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions on Knowledge and Data Engineering (TKDE)</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="5879" to="5900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graphprompt: Unifying pre-training and downstream tasks for graph neural networks</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="417" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Demystifying structural disparity in graph neural networks: Can one size fit all?</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scaling data-constrained language models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Muennighoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Le</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tazi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gppt: Graph pre-training and prompt tuning to generalize graph neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1717" to="1727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Graphgpt: Graph instruction tuning for large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="491" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Higpt: Heterogeneous graph language model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Omnivl: One foundation model for image-language and video-language tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="5696" to="5710" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Internimage: Exploring large-scale vision foundation models with deformable convolutions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="14408" to="14419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simplifying graph convolutional networks</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6861" to="6871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Automated self-supervised learning for recommendation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="992" to="1002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Opengraph: Towards open graph foundation models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2403.01121</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning how to propagate messages in graph neural networks</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1894" to="1903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Self-supervised learning of graph neural networks: A unified review</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2412" to="2429" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>TPAMI)</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Language is all a graph needs</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1955" to="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Graph contrastive learning automated</title>
		<author>
			<persName><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="12121" to="12132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Graph contrastive learning with augmentations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5812" to="5823" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cross-domain few-shot graph classification with a reinforced task coordinator</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="4893" to="4901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">All in one and one for all: A simple yet effective method towards cross-domain graph pretraining</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Graph contrastive learning with adaptive augmentation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="2069" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
